Using
Lime
for
Interpreting
NLP.
NLP
can
present
many
difficulties
in‚Ä¶
By
LIA
Longer
Medium
Open
in
app
Home
Notifications
Lists
Stories
Write
LIA
Longer
Follow
Feb
26
¬∑
3
min
read
Save
Using
Lime
for
Interpreting
NLP
can
present
many
difficulties
in
interpretation.
Without
a
good
idea
of
why
your
model
is
performing
the
way
it
"does,"
it
can
both
be
difficult
to
determine
what
you
might
attempt
to
do
to
improve
its
performance
or
if
you
should
trust
that
it
generalizes
outside
the
limits
of
your
data.
Lime
provides
a
decent
and
fairly
easy
to
use
means
of
helping
in
interpreting
text
classifiers
and
any
models
that
act
on
tables.
It
is
build
to
integrate
Scikit-learn
models
and
is
relatively
easy
to
use.
Lime
can
be
installed
using
pip
commands
or
by
cloning
their
GitHub.
Pip
install
lime
If
you
want
to
use
it
with
a
"Scikit-learn,"
the
process
is
fairly
simple.
I
will
give
an
example
using
one
of
my
sentiment
analysis
projects
that
focused
on
predicting
sentiment
towards
Apple
products.
"First,"
make
a
pipeline
from
whatever
"standardizers,"
"vectorizes,"
and
models
you
used.
I
used
tide
vectorize
and
a
random
forest
model
in
one
of
the
models
I
constructed
during
the
project.
Next
you
can
pick
an
example
from
your
data
to
"examine,"
here
I
picked
an
example
from
the
negative
sentiment
tweets
in
my
dataset
because
the
models
were
struggling
with
that
class.
You
can
then
create
an
explainer
object
and
input
the
labels
of
your
target
classes.
"Finally,"
you
can
create
and
display
an
explanation
by
inputting
the
example
"text,"
and
the
predicted
probabilities
to
the
explain
instance
method
of
the
explainer
object.
We
can
see
from
this
example
that
the
model
is
performing
poorly
on
this
"example,"
and
can
get
a
feel
for
why.
It
is
paying
attention
to
words
like
app
and
iPad
which
were
quite
frequent
in
this
data
due
to
the
way
it
was
"collected,"
but
the
model
was
ignoring
relevant
words
that
clearly
indicate
the
negative
sentiment
of
this
tweet
like
"‚Äúcrashing‚Äù,"
‚Äúseriously‚Äù
or
‚Äúlost‚Äù.
If
you
want
to
use
Lime
with
a
Keras
"model,"
the
process
is
a
bit
less
straightforward.
"First,"
you
will
need
to
make
a
wrapper
for
the
"model,"
so
it
can
be
placed
in
a
pipeline
object.
This
is
fairly
straightforward
using
a
Scleras
wrapper
or
the
deprecated
TensorFlow
"wrapper,"
which
presently
still
functions.
Just
make
a
function
defining
your
model
and
input
it
into
the
wrapper
object.
You
can
then
place
the
wrapper
into
a
pipeline
object
just
like
any
Scikit-learn
model
along
with
any
preprocessing
you
need
such
as
"tokenization,"
"padding,"
etc.
You
can
use
it
the
same
way
as
before.
With
the
help
of
Lime
we
can
"see,"
not
just
that
this
Keras
model
did
a
better
job
at
predicting
with
high
probability
that
this
tweet
had
negative
"sentiment,"
but
can
also
get
a
clearer
idea
of
why
by
seeing
what
parts
of
the
tweet
the
model
is
paying
attention
to.
Unlike
the
previous
model
the
Keras
model
notices
words
that
clearly
indicate
the
negative
sentiment
of
this
tweet
like
"‚Äúcrashing‚Äù,"
‚Äúseriously‚Äù
or
‚Äúlost‚Äù.
This
difference
can
help
give
one
a
bit
more
confidence
in
its
predictions
outside
this
"dataset,"
since
it
is
less
likely
that
its
successes
are
due
to
mere
artifacts
or
peculiarities
in
the
particular
tweets
that
were
used
in
training
this
model.
For
more
"info,"
check
out
the
Lime
GitHub
which
has
useful
tutorials
on
everything
that
can
be
done
with
Lime
including
explanations
of
image
analysis.
2
2
2
More
from
LIA
Longer
Follow
LIA
is
a
philosophy
lecturer
having
earned
her
Ph.D.
from
University
of
Nebraska
in
2018
and
is
also
currently
an
aspiring
data
scientist
Love
podcasts
or
audiobooks?
Learn
on
the
go
with
our
new
app.
Try
Knowable
Recommended
from
Medium
Umang
Tiwari
Blood
Cell
classification
using
Deep
Learning
on
Canvas
Platform
Dominik
Haiti
in
Towards
Data
Science
Creating
and
Deploying
a
Python
Machine
Learning
Service
Jack
Daniel
Handwritten
Digit
Recognition
by
using
CNN
Andy
McMahon
in
stream
Reinforcement
Learning
in
the
Supply
Chain
May
in
The
Web
Tub
Create
Your
First
Machine
Learning
Mobile
Application
Deal
Zhang
in
Towards
Data
Science
Create
an
Image
Classification
Web
App
using
PyTorch
and
Stream
lit
Hugo
Contreras
Small
World
Networks
Sam
kit
Shah
Recognizing
Face
Using
Transfer
Learning
About
Help
Terms
Privacy
Get
the
Medium
app
Get
started
LIA
Longer
6
Followers
LIA
is
a
philosophy
lecturer
having
earned
her
Ph.D.
from
University
of
Nebraska
in
2018
and
is
also
currently
an
aspiring
data
scientist
Follow
More
from
Medium
Nikhil
Versa
BERT
Rediscovers
the
Classical
NLP
Pipeline
Nicola
Ghana
How
To
‚Äî
Questions
Generation
using
Transformers
ü§ó
NNICCCeylonA
New
Approach
to
the
FNC
‚Äî
Fake
News
Competition
"Dataset,"
Placing
2nd
Overall
with
Half
the
ML
Ashutosh
UPathwayNeed
for
FFertilizationin
NLP:
‚ÄúText2Vector‚Äù
Conversion
in
Machine
Learning
.Help
Status
Writers
Blog
Careers
Privacy
Terms
About
Knowable

Introduction
to
Natural
Language
Processing
in
Text
Classification
by
Samoa
Maria
Medium
Open
in
app
Home
Notifications
Lists
Stories
Write
Samoa
Maria
Follow
Mar
4
·
3
min
read
Save
Introduction
to
Natural
Language
Processing
in
Text
Classification
With
the
enormous
amount
of
textual
data
"available,"
it
has
become
a
necessity
to
create
intelligent
software
that
can
process
information
faster.
Natural
Language
Processing
NLP
is
an
amalgamation
of
techniques
employed
for
processing
text.
A
simple
and
popular
application
of
NLP
is
text
classification.
A
more
complicated
application
is
Amazon’s
‘Alexa’.
Applications
of
NLP
can
eliminate
boring
"tasks,"
reduce
costs
and
increase
the
efficiency
of
an
organization.
To
answer
how
‘Alexa’
with
impressive
accuracy
interprets
the
human
language
is
a
hard
task.
"However,"
understanding
a
basic
text
classification
model
is
important
to
solve
harder
problems.
So
how
does
a
text
classification
model
work?
Text
classification
is
just
like
any
other
classification
"problem,"
except
"texts,"
need
to
be
processed
differently.
A
classification
model
classifies
an
input
into
an
output
which
can
be
category
‘0’
or
‘1’.
Te
model
learns
the
relationship
between
input
and
output
from
train
data
"seen,"
this
step
is
called
training.
After
"training,"
the
model
can
be
used
for
prediction
on
test
data
unseen.
The
model
has
seen
and
learned
the
train
data
with
higher
accuracy
than
test
data.
The
objective
is
always
to
aim
for
a
high
prediction
accuracy
of
the
model
on
test
data.
In
order
to
use
a
classification
"model,"
we
need
to
understand
how
text
is
processed
and
converted
into
a
mathematical
object.
NLP
techniques
are
utilized
for
text
processing.
A
text
can
contain
infinite
"words,"
"emojis,"
"links,"
"punctuation,"
"etc.,"
and
not
every
single
word
is
equally
important.
Consider
stop
words
like
"‘the’,"
"‘a’,"
"‘I’,"
"etc.,"
which
are
frequently
used
and
convey
very
little
about
the
topic
of
the
texts.
"Therefore,"
it
is
wise
to
filter
words
from
texts
that
don’t
convey
useful
information.
The
text
‘
When
my
friend
presented
me
with
a
"gift,"
I
was
overflowed
with
happiness’
after
filtering
out
words
becomes
‘friend
presented
with
gift
overflowed
with
happiness’.
Our
aim
is
to
shrink
a
large
text
into
as
few
words
as
possible.
Words
also
need
to
be
stemmed.
Stemming
is
the
process
of
converting
a
word
into
its
root
word.
For
"example,"
‘happy’
is
the
root
word
for
‘happily’
and
‘happiness’.
A
dictionary
containing
words
from
all
the
texts
in
train
data
is
then
created
to
represent
the
entire
vocabulary.
Keeping
only
the
root
words
helps
to
shrink
the
size
of
the
"dictionary,"
as
only
‘happy’
will
be
kept
instead
of
‘happily’
and
‘happiness’.
The
text
‘friend
presented
with
gift
overflowed
with
happiness’
after
stemming
becomes
‘friend
present
with
gift
overflow
with
happy’.
After
Stemming
is
vectorization.
Each
text
is
converted
into
a
vector
containing
0’s
and
1’s.
The
size
of
the
vector
is
the
length
of
the
dictionary.
The
dictionary
contains
the
vocabulary
from
all
the
texts
from
the
train
data.
For
"instance,"
if
the
dictionary
based
on
example
is
1:
"‘friend’,"
"2:’with’,"
"3:’present’,"
4:
"‘overflow’,"
"5:’gift’,"
"6:’happy’,"
then
the
vectorized
form
of
partial
text
‘overflow
with
happy’
would
be
"0,1,0,1,0,1."
The
1’s
correspond
to
the
words
in
the
"2nd,"
4th
and
6th
position
in
the
dictionary.
This
process
is
called
Vectorization.
After
all
the
textual
data
is
"cleaned,"
"stemmed,"
and
"vectorized,"
it
can
be
used
for
training
a
classification
model.
"Regression,"
tree
"methods,"
and
SVM
are
some
popular
classification
models.
The
architecture
and
performance
of
the
different
models
are
a
topic
for
another
discussion.
Only
a
subset
of
important
NLP
techniques
is
discussed
here.
The
complexity
and
the
variety
of
the
techniques
increase
depending
on
the
problem.
"Nevertheless,"
this
brief
discussion
touches
the
skeleton
of
the
whole
process
and
aims
to
inspire
starters!
References:
1
Discover.bot.
2022.
online
Available
at:
HTTPS:discover.botwp-contentuploads202003measuring-chatbot-performance-1668x813.jpg
Accessed
3
March
2022.
2
Chou
"bey,"
"V.,"
2020.
Text
classification
using
CNN.
Online
Medium.
Available
at:
HTTPS:medium.comvoice-tech-podcasttext-classification-using-cnn-9ade8155dfb9
Accessed
3
March
2022.
3
M.
Ankara
and
R.
M.
R.
"Budget,"
“Performance
analysis
of
Ensemble
methods
on
Twitter
sentiment
analysis
using
NLP
"techniques,”"
Proceedings
of
the
2015
IEEE
9th
International
Conference
on
Semantic
Computing
IEEE
CSC
"2015,"
"2015,"
pp.
"169–170,"
DOI:
10.1109ICOSC.2015.7050801.
More
from
Samoa
Maria
Follow
Love
podcasts
or
audiobooks?
Learn
on
the
go
with
our
new
app.
Try
Knowable
Recommended
from
Medium
Vegetable
Plane
Maximum
likelihood
Estimate
MLE
—
an
Introduction
Buttercup
Naive
Bayes
Classifier
Runs
Alter
Vascular
in
AIN311
Fall
2021
Projects
Week
4—
Audio
Captioning
AIT
Samurai
Unveiling
Mathematics
behind
Boost
Device
meta
Utilizing
Deep
Studying
to
Annotate
the
Protein
Universe
Desiree
Patel
in
VisionWizard
Transcode
from
Facebook
AI
airbag
sen
in
Analytics
Vichy
Text
Classification
—
From
Bag-of-Words
to
BERT
—
Part
6
BERT
Chang
sin
Lee
Understanding
K
Means
Clustering
Graphically
About
Help
Terms
Privacy
Get
the
Medium
app
Get
started
Samoa
Maria
Follow
More
from
Medium
Jeff
Marvel
Constrained
Resource
Allocation
Using
SciPy
Minimize
Nithinvarma
Methodology
for
Warehouse
Optimization
by
K-means
Clustering
Algorithm
Şahin
Parker
Traffic
Sign
Recognition
using
PyTorch
and
CNN
Manoj
Damon
Image
Classification
Using
Deep
Learning
with
CNN
and
Keras
Help
Status
Writers
Blog
Careers
Privacy
Terms
About
Knowable
